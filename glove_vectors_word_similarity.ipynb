{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we first load the glove vectors as a dictionary - `embeddings_index`\n",
    "`embeddings_index['banana']` would give some 100 length vector for the word `'banana'`\n",
    "\n",
    "The object `GLOVE_DIR` points to the text file which containes the vectors, but it could also be downloaded form http://nlp.stanford.edu/data/glove.6B.zip and saved on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "GLOVE_DIR = '/home/harshit/Documents/glove.6B/'\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.34028  ,  0.46436  , -0.083324 ,  0.20186  , -0.17831  ,\n",
       "       -0.4663   ,  0.61793  ,  0.30129  ,  0.5728   , -0.34783  ,\n",
       "       -0.9216   ,  0.30484  ,  0.30382  ,  0.58035  ,  0.12112  ,\n",
       "        0.77288  ,  1.1547   , -0.576    ,  0.51471  ,  0.21552  ,\n",
       "        0.21106  ,  0.67875  ,  1.1962   ,  0.11142  ,  0.50809  ,\n",
       "        1.1873   ,  0.035288 , -0.88952  ,  0.042803 , -0.36714  ,\n",
       "        0.37993  ,  0.61945  ,  1.0194   , -0.95084  , -0.0072258,\n",
       "        0.69454  ,  0.38692  , -0.18544  ,  0.2885   , -0.81279  ,\n",
       "       -0.46473  , -0.82623  ,  0.42778  , -0.14064  ,  0.30173  ,\n",
       "        0.074418 , -0.40044  ,  0.33969  , -0.62917  , -0.054449 ,\n",
       "       -0.78469  ,  0.2354   , -0.78359  ,  0.74708  , -0.31074  ,\n",
       "       -0.07038  , -0.34623  ,  0.33849  ,  0.89621  ,  0.30288  ,\n",
       "        0.012978 ,  0.020869 , -0.14436  , -0.40914  ,  0.16651  ,\n",
       "       -0.88124  , -0.078419 ,  0.048156 ,  0.27032  , -0.81761  ,\n",
       "        0.027778 ,  0.62487  ,  0.1549   , -0.15838  ,  0.088675 ,\n",
       "        0.063411 , -0.14473  , -0.0066816, -0.18535  ,  1.5642   ,\n",
       "        0.3726   , -0.81706  , -0.021685 ,  0.91209  , -0.35784  ,\n",
       "       -0.98389  , -0.37103  , -0.10909  ,  0.18898  , -0.33884  ,\n",
       "       -0.058326 ,  0.41438  , -1.0411   , -0.42643  , -0.50664  ,\n",
       "       -0.75863  , -0.15815  , -0.1831   ,  0.7343   , -0.26852  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['banana']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's find the top 7 words that are closest to 'compute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "u = embeddings_index['compute']\n",
    "norm_u = np.linalg.norm(u)\n",
    "similarity = []\n",
    "\n",
    "\n",
    "for word in embeddings_index.keys():\n",
    "    v = embeddings_index[word]\n",
    "    cosine = np.dot(u, v)/norm_u/np.linalg.norm(v)\n",
    "    similarity.append((word, cosine))\n",
    "\n",
    "\n",
    "print(len(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('compute', 1.0),\n",
       " ('calculate', 0.7222063),\n",
       " ('algorithm', 0.64410573),\n",
       " ('computed', 0.6136235),\n",
       " ('algorithms', 0.61343825),\n",
       " ('equivalently', 0.59991395),\n",
       " ('formula_1', 0.5970425),\n",
       " ('formula_2', 0.5948518),\n",
       " ('formula_3', 0.593129),\n",
       " ('formula_5', 0.5920933)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(similarity, key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's do vector algebra.\n",
    "\n",
    "### First we subtract the vector for `france` from `paris`. This could be imagined as a vector pointing from country to its capital. Then we add the vector of `nepal`. Let's see if it does point to the country's capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "output = embeddings_index['paris'] - embeddings_index['france'] + embeddings_index['nepal']\n",
    "norm_out = np.linalg.norm(output)\n",
    "\n",
    "similarity = []\n",
    "for word in embeddings_index.keys():\n",
    "    v = embeddings_index[word]\n",
    "    cosine = np.dot(output, v)/norm_out/np.linalg.norm(v)\n",
    "    similarity.append((word, cosine))\n",
    "\n",
    "\n",
    "print(len(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kathmandu', 0.8039164),\n",
       " ('nepal', 0.75638914),\n",
       " ('katmandu', 0.70364904),\n",
       " ('dhaka', 0.6556245),\n",
       " ('nepali', 0.6497056),\n",
       " ('delhi', 0.64691),\n",
       " ('bangkok', 0.6085232)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(similarity, key=lambda x: x[1], reverse=True)[:7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
